{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42142d60",
   "metadata": {},
   "source": [
    "<img src=\"https://www.th-koeln.de/img/logo.svg\" style=\"float:right;\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756ba942",
   "metadata": {},
   "source": [
    "# 12th exercise: <font color=\"#C70039\">Deep Learning Basics: Preprocessing, Encoding and Initial Setup</font>\n",
    "* Course: <a href=\"https://www.gernotheisenberg.de/time_series_forecasting.html\">Time Series Forecasting (TSF)</a>\n",
    "* Lecturer: <a href=\"https://www.gernotheisenberg.de/uebermich.html\">Gernot Heisenberg</a>\n",
    "* Date:   23.03.2025\n",
    "\n",
    "<img src=\"./images/DL1.jpg\" style=\"float: center;\" width=\"450\">\n",
    "\n",
    "---------------------------------\n",
    "**GENERAL NOTE 1**: \n",
    "Please make sure you are reading the entire notebook, since it contains a lot of information on your tasks (e.g. regarding the set of certain paramaters or a specific computational trick), and the written mark downs as well as comments contain a lot of information on how things work together as a whole. \n",
    "\n",
    "**GENERAL NOTE 2**: \n",
    "* Please, when commenting source code, just use English language only. \n",
    "* When describing an observation please use English language, too\n",
    "* This applies to all exercises throughout this course.  \n",
    "\n",
    "---------------------\n",
    "\n",
    "### <font color=\"ce33ff\">DESCRIPTION OF THE NOTEBOOK CONTENT</font>:\n",
    "This notebook allows you for learning about the initial first steps, including data preprocessing and especially data encoding when planning to forecast a time series by Deep Learning approaches. \n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### <font color=\"FFC300\">TASKS</font>:\n",
    "The tasks that you need to work on within this notebook are always indicated below as bullet points. \n",
    "If a task is more challenging and consists of several steps, this is indicated as well. \n",
    "Make sure you have worked down the task list and commented your doings. \n",
    "This should be done by using markdown.<br> \n",
    "<font color=red>Make sure you don't forget to specify your name and your matriculation number in the notebook.</font>\n",
    "\n",
    "**YOUR TASKS in this exercise are as follows**:\n",
    "1. import the notebook to Google Colab or use your local machine.\n",
    "2. make sure you specified you name and your matriculation number in the header below my name and date. \n",
    "    * set the date too and remove mine.\n",
    "3. read the entire notebook carefully \n",
    "    * add comments whereever you feel it necessary for better understanding\n",
    "    * run the notebook for the first time.\n",
    "    * understand the output\n",
    "4. Prepare a data set for DL and perform preprocessing\n",
    "    * Download data set from the UCI Machine Learning Repository:\n",
    "        * https://archive.ics.uci.edu/ml/datasets/Beijing+Multi-Site+Air-Quality+Data.\n",
    "    * Read the data and plot the target\n",
    "    * Remove unnecessary columns\n",
    "    * Identify whether there is daily seasonality and encode the time accordingly \n",
    "    * Split your data into training, validation and testing sets.\n",
    "    * Scale the data using MinMaxScaler.\n",
    "    * Save the train, validation and test sets to be used later.\n",
    "-----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3920ed9-ec29-4da3-b0b5-7b182d7c7be9",
   "metadata": {},
   "source": [
    "# PART I - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9051f2-c306-46e5-be38-a71eb5674272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce81bafc-86b1-4684-b838-a7ccc887fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/DL/Metro_Interstate_Traffic_Volume.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145589f-3096-48ae-8a24-d827b01533b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_time'] = pd.to_datetime(df['date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f09279-06b3-430c-abf9-ed37e5b576af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='date_time', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fecc93-1581-4a8f-af65-d32c5fbe6df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6718ef7b-f4c0-44ba-b682-7ce462d69a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = list(pd.date_range('2012-10-02 09:00:00', '2018-09-30 23:00:00', freq='H'))\n",
    "print(len(date_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4645413-e2a3-436c-a0b9-63c21e5cffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({'date_time': date_range})\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c3f6ef-0987-4e91-9553-b4d48f89e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(new_df, df, how='left', on='date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6459de23-9e28-4839-b9e9-cd07465c8aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202e5fc2-4b2e-4d7d-a50f-f2382bdc74ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d56dd5-c8f1-4719-94d8-56ac30685345",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13,6))\n",
    "\n",
    "ax.plot(full_df.traffic_volume)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Traffic volume')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562354c4-62d8-46bb-836b-0b8fcff34dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[35000:].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc1752f-1ae7-4b95-9ce5-81902987f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df[35000:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e56f3-aed6-426f-b135-54479d276c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d5a45-9f5d-498a-b5e2-d44a75d3352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.drop(['holiday', 'weather_main', 'weather_description'], axis=1)\n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f238c-01f3-438a-9df6-97219dd8f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.fillna(full_df.groupby(full_df.date_time.dt.hour).transform('median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ae800-64d9-4fac-aad0-4b81c2f0fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6813bdf-08ae-4078-a97b-e2c1dd6b4c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13,6))\n",
    "\n",
    "ax.plot(full_df.traffic_volume)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Traffic volume')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b6102-fbb8-4729-9249-3a1aeb48b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv('./data/DL/metro_interstate_traffic_volume_preprocessed.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b46aef1-625d-42f9-822a-d85ef39b36a9",
   "metadata": {},
   "source": [
    "# PART II - Data Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f2bfe9-9921-4427-9452-bbf6b422fe96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load all remaining libs that have not been loaded in the first import section\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Lambda, Reshape, RNN, LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7760adae-e9b6-482e-b68a-c0b0dfea7e48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# useful settings\n",
    "plt.rcParams['figure.figsize'] = (10, 7.5)\n",
    "plt.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c75f1c2-649c-4717-b84c-72b73dc22a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c049870-cfd2-414b-a652-97a716678613",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/DL/metro_interstate_traffic_volume_preprocessed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab57db0-36dd-4468-934d-549d155748e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be7d2f-8671-437a-aca2-0354f00babb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43430190-0ca0-4405-9d4a-196e4a36db66",
   "metadata": {},
   "source": [
    "#### Visualization section\n",
    "Visualize the evolution of the traffic volume over time. \n",
    "Since the dataset is very large, with more than 17,000 records, plot only the first 400 data points,\n",
    "which is roughly equivalent to two weeks of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f0f3fd-2f66-4898-85da-a9670b07fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['traffic_volume'])\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Traffic volume')\n",
    "\n",
    "plt.xticks(np.arange(7, 400, 24), ['Friday', 'Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "plt.xlim(0, 400)# plot the first 400 data points only \n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a82d3c-8e38-4e11-9938-651b7adae397",
   "metadata": {},
   "source": [
    "Notice a clear daily seasonality, since the traffic volume is lower at the start and end of each day.\n",
    "Also see a smaller traffic volume during the weekends. \n",
    "\n",
    "As for the trend, two weeks of data (0:400) is likely insufficient to draw a reasonable conclusion but it seems that the volume is neither increasing nor decreasing\n",
    "over time in the figure.\n",
    "\n",
    "Also plot the hourly temperature, as it will be a target for the multi-output models. Here, we will expect to see both yearly and daily seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a2ff48-4975-4359-a484-104a4f3b8fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['temp'])\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Temperature (K)')\n",
    "\n",
    "plt.xticks([2239, 10999], [2017, 2018])\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb911fc-fc49-4543-80de-71c91a2fa24d",
   "metadata": {},
   "source": [
    "Visualize the first two weeks again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b247ef15-f2a4-4db7-8f7f-a6f01864fffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['temp'])\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Temperature (K)')\n",
    "\n",
    "plt.xticks(np.arange(7, 400, 24), ['Friday', 'Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "plt.xlim(0, 400) # two week again\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb487ca-f0c6-4728-9ddc-042c2b18b2b6",
   "metadata": {},
   "source": [
    "The yearly seasonality in the plot (upper one) should be due to the seasons in the year, while the daily seasonality (lower one) will be due to the fact that temperatures tend to be lower at night and higher during the day, although the data is a bit noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d72b543-7535-4d3a-a866-499728e1302f",
   "metadata": {},
   "source": [
    "#### Feature engineering and data splitting\n",
    "\n",
    "use the describe method in order to get a good overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300b04b2-3771-4a84-8628-8258c82f10d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fa7106-b295-4010-b318-996e4986f3c8",
   "metadata": {},
   "source": [
    "##### Remove unusable features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d811b4f-72eb-468e-b34f-ca32fadde57f",
   "metadata": {},
   "source": [
    "From the output, you’ll notice that rain_1h is mostly 0 throughout the dataset, as its third quartile is still at 0. Since at least 75% of the values for rain_1h are 0, it is unlikely that it is a strong predictor of traffic volume. Thus, this feature will be removed. \n",
    "\n",
    "Looking at snow_1h, you’ll notice that this variable is at 0 through the entire dataset. This is easily observable, since its minimum and maximum values are both 0.\n",
    "Thus, this is not predictive of the variation in traffic volume over time. This feature will also be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2230b2-e46a-4ace-8088-9ea15688c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['rain_1h', 'snow_1h']\n",
    "df = df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea332d0f-da37-4dd5-939b-c7912a01745f",
   "metadata": {},
   "source": [
    "##### Enconding of the time\n",
    "\n",
    "Right now, the date_time feature is not usable by the models, since it is a datetime string. Thus convert it into a numerical value.\n",
    "A simple way to do that is to express the date as a number of seconds. This is achieved through the use of the timestamp method from the datetime library.\n",
    "\n",
    "<font color = red>NOTE:</font>\n",
    "However, this leads us to losing the cyclical nature of time, because the number of seconds simply increases linearly with time.\n",
    "\n",
    "Therefore, we must apply a transformation to recover the cyclical behavior of time. A simple way to do that is to apply a sine transformation. We know that the\n",
    "sine function is cyclical, bounded between –1 and 1. This will help us regain part of the cyclical property of time.\n",
    "\n",
    "However, we need to confirm the seasonality cycle in the data. For this purpose we will use the power spectrum visualization by means of a Fast Fourier Transformation (FFT). This FFT maps the time series into the frequency space and plots the absolute frequenvy (absolute Häufigkeit) over the time frequency in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d432c8b-71ad-4656-93cd-a194a450b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_s = pd.to_datetime(df['date_time']).map(datetime.datetime.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec38ccf0-9102-4a3b-905f-2f266dd770bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft = tf.signal.rfft(df['traffic_volume'])\n",
    "f_per_dataset = np.arange(0, len(fft))\n",
    "\n",
    "n_sample_h = len(df['traffic_volume'])\n",
    "hours_per_week = 24 * 7\n",
    "weeks_per_dataset = n_sample_h / hours_per_week\n",
    "\n",
    "f_per_week = f_per_dataset / weeks_per_dataset\n",
    "\n",
    "plt.step(f_per_week, np.abs(fft))\n",
    "plt.xscale('log')\n",
    "plt.xticks([1, 7], ['1/week', '1/day'])\n",
    "plt.xlabel('Frequency [Hz]', color ='r')\n",
    "plt.ylabel('#', color ='r')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a9694e-5637-4c3a-b01b-f5c0c6501819",
   "metadata": {},
   "source": [
    "Amplitude of the weekly and daily seasonality in our target. See that the amplitude of the weekly seasonality is lower than the daily seasonality peak. \n",
    "Therefore, we indeed have daily seasonality for our target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34924c10-f990-4e24-a169-3cdd42ed8b4e",
   "metadata": {},
   "source": [
    "#### Applying the sine / cosine encoding\n",
    "\n",
    "With a single sine transformation, we regain some of the cyclical property that was lost when converting to seconds. \n",
    "However, at this point, 12 p.m. is equivalent to 12 a.m. and 5 p.m. is equivalent to 5 a.m. \n",
    "This is undesired, as we want to distinguish between morning and afternoon. Thus, we’ll apply a cosine transformation. We know that\n",
    "cosine is out of phase with the sine function. This allows us to distinguish between 5 a.m. and 5 p.m., \n",
    "expressing the cyclical nature of time in a day. After that, we can remove the date_time column from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de7b3a-95b4-43c7-9001-8c5853a90fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The timestamp is in seconds, so we must calculate the number of seconds in a day\n",
    "# before applying the sine/cosine transformation.\n",
    "day = 24 * 60 * 60\n",
    "\n",
    "df['day_sin'] = (np.sin(timestamp_s * (2*np.pi/day))).values\n",
    "df['day_cos'] = (np.cos(timestamp_s * (2*np.pi/day))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5c6960-00e6-4f65-9a20-63d46302f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['date_time'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d612024-fabf-4948-b7c7-cda894cac80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(50).plot.scatter('day_sin','day_cos').set_aspect('equal');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6def81-7659-4f97-ab21-a9318836911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the old timestamp in seconds encoding\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(timestamp_s)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Number of seconds')\n",
    "\n",
    "plt.xticks([2239, 10999], [2017, 2018])\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30100b0-b4f8-4d71-8f60-d97a075a9b2d",
   "metadata": {},
   "source": [
    "##### Data split (train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d9c8d-daf4-4c66-a034-cdf24f7ee0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "\n",
    "# Split 70:20:10 (train:validation:test)\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0707737-13e7-4d6a-b25a-5cbd7d863762",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Scale all feature to be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a2ff62-a740-48e2-953c-11a5f028def9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_df)\n",
    "\n",
    "train_df[train_df.columns] = scaler.transform(train_df[train_df.columns])\n",
    "val_df[val_df.columns] = scaler.transform(val_df[val_df.columns])\n",
    "test_df[test_df.columns] = scaler.transform(test_df[test_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810be384-d698-4edf-b845-dfeb22ff8beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb854f-daaa-4ca7-9bad-0d1650de3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./data/DL/train.csv')\n",
    "val_df.to_csv('./data/DL/val.csv')\n",
    "test_df.to_csv('./data/DL/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7a61c-9077-4552-aedb-8d26df1b75dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
