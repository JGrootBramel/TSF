{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07369c1c-d4c6-40c6-a7ef-e4183f7822b8",
   "metadata": {},
   "source": [
    "<img src=\"https://www.th-koeln.de/img/logo.svg\" style=\"float:right;\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cccec2c-fde7-4d6e-ad95-585faa8746fa",
   "metadata": {},
   "source": [
    "# 13th exercise: <font color=\"#C70039\">Deep Learning: Data Windowing</font>\n",
    "* Course: <a href=\"https://www.gernotheisenberg.de/time_series_forecasting.html\">Time Series Forecasting (TSF)</a>\n",
    "* Lecturer: <a href=\"https://www.gernotheisenberg.de/uebermich.html\">Gernot Heisenberg</a>\n",
    "* Date:   24.03.2025\n",
    "\n",
    "<img src=\"./images/datawindowing.jpg\" style=\"float: center;\" width=\"450\">\n",
    "\n",
    "---------------------------------\n",
    "**GENERAL NOTE 1**: \n",
    "Please make sure you are reading the entire notebook, since it contains a lot of information on your tasks (e.g. regarding the set of certain paramaters or a specific computational trick), and the written mark downs as well as comments contain a lot of information on how things work together as a whole. \n",
    "\n",
    "**GENERAL NOTE 2**: \n",
    "* Please, when commenting source code, just use English language only. \n",
    "* When describing an observation please use English language, too\n",
    "* This applies to all exercises throughout this course.  \n",
    "\n",
    "---------------------\n",
    "\n",
    "### <font color=\"ce33ff\">DESCRIPTION OF THE NOTEBOOK CONTENT</font>:\n",
    "This notebook allows you for learning about how to implement a DataWindow class which supports the forecasting activities using Deep Learning approaches and makes them extremely simple. \n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### <font color=\"FFC300\">TASKS</font>:\n",
    "The tasks that you need to work on within this notebook are always indicated below as bullet points. \n",
    "If a task is more challenging and consists of several steps, this is indicated as well. \n",
    "Make sure you have worked down the task list and commented your doings. \n",
    "This should be done by using markdown.<br> \n",
    "<font color=red>Make sure you don't forget to specify your name and your matriculation number in the notebook.</font>\n",
    "\n",
    "**YOUR TASKS in this exercise are as follows**:\n",
    "1. import the notebook to Google Colab or use your local machine.\n",
    "2. make sure you specified you name and your matriculation number in the header below my name and date. \n",
    "    * set the date too and remove mine.\n",
    "3. read the entire notebook carefully \n",
    "    * add comments whereever you feel it necessary for better understanding\n",
    "    * run the notebook for the first time.\n",
    "    * understand the output\n",
    "4. Data windowing with the pollution data set\n",
    "    * In the previous exercise, we prepared the air pollution dataset for deep learning modeling. Now we are going to use the training set, validation set and test set to build baseline models and evaluate them.\n",
    "    * For each type of model, follow the steps below. Remember that the target for the singlestep and multi-step model is the concentration of NO2 and the targets for the multi-output model are the concentration of NO2 and temperature. \n",
    "    * For the single-step model:\n",
    "        * Build a baseline model that predicts the last known value.\n",
    "        * Plot it.\n",
    "        * Evaluate its performance using the mean absolute error (MAE) and store it for comparison in a dictionary.\n",
    "    * For the multi-step model:\n",
    "        * Build a baseline that predicts the last known value over a horizon of 24 hours.\n",
    "        * Build a baseline model that repeats the last 24 hours.\n",
    "        * Plot the predictions of both models.\n",
    "        * Evaluate both models using the MAE and store their performance.\n",
    "    * For the multi-output model:\n",
    "        * Build a baseline model that predicts the last known value.\n",
    "        * Plot it.\n",
    "        * Evaluate its performance using the MAE and store it for comparison in a dictionary.\n",
    "-----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39b69a-a598-41a5-aee4-e541b6d959c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-above",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('tf.keras.__version__=',tf.keras.__version__)\n",
    "print(\"tf.__version__=\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-relations",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 7.5)\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a55db",
   "metadata": {},
   "source": [
    "# 13.1 Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d8333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/DL/train.csv', index_col=0)\n",
    "val_df = pd.read_csv('./data/DL/val.csv', index_col=0)\n",
    "test_df = pd.read_csv('./data/DL/test.csv', index_col=0)\n",
    "\n",
    "print(train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1973d2",
   "metadata": {},
   "source": [
    "## 13.1 Creating windows of data\n",
    "### 13.1.1 Split and visualize the data set into chunks of 24 data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25cae63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for n in range(0,17,2):\n",
    "    start = 24*n\n",
    "    stop = 24*(n+1)\n",
    "    ax.plot(train_df.traffic_volume[start:stop], marker='s', color='blue', label='input')\n",
    "    ax.plot(train_df.traffic_volume[stop:2*stop], marker='x', color='red', label='label')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Traffic volume')\n",
    "\n",
    "plt.xticks(np.arange(7, 400, 24), ['Friday', 'Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "plt.xlim(0, 400)\n",
    "\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7284e0c6",
   "metadata": {},
   "source": [
    "### 13.1.2 Implementing the `DataWindow` class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacd3a2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataWindow():\n",
    "    '''the initialization function of the class assigns the variables and manages the indices of the inputs and the labels.'''\n",
    "    def __init__(self, input_width, label_width, shift, \n",
    "                 train_df=train_df, val_df=val_df, test_df=test_df, \n",
    "                 label_columns=None):\n",
    "        \n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        \n",
    "        # Name of the column that we wish to predict\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            # Create a dict with the name and index of the label column.\n",
    "            # This will be used for visulization later.\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        # Create a dict with the name and index of each column. \n",
    "        # This will be used to separate the features from the target variable.\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "        \n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        self.total_window_size = input_width + shift\n",
    "        \n",
    "        ''' The slice function returns a slice object that specifies how\n",
    "            to slice a sequence. In this case, it says that the input slice \n",
    "            starts at 0 and ends when we reach the input_width.'''\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        # Assign indices to the inputs. These are useful for visualization.\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "        \n",
    "        # Get the index at which the label starts. In this case, it is the total window size minus the width of the label.\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        # The same steps that were applied for the inputs are applied for labels, too.\n",
    "        self.label_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.label_slice]\n",
    "    \n",
    "    ''' The split_to_inputs_labels() function splits the window between inputs and labels, \n",
    "        so that the models, later, can make predictions based on the inputs and measure an error metric against the labels.\n",
    "        It will separate the big data window into two windows: \n",
    "        one for the inputs and the other for the labels, as shown in the lecture slides!'''\n",
    "    def split_to_inputs_labels(self, features):\n",
    "        # slice the window to get the inputs using the input_slice defined in __init__.\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        # slice the window to get the labels using the labels_slice defined in __init__.\n",
    "        labels = features[:, self.label_slice, :]\n",
    "        # If there is more than one target let's stack the labels.\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:,:,self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "        # The shape will be [batch, time, features]. \n",
    "        # At this point, we only specify the time dimension and allow the batch and feature dimensions\n",
    "        # to be defined later (see below).    \n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "        \n",
    "        return inputs, labels\n",
    "    \n",
    "    ''' Define a function to plot the input data, the predictions and the actual values for comparison. \n",
    "        \n",
    "        Since we will be working with many time windows, we’ll show only the plot of three time windows (default max_subplots), \n",
    "        but this parameter can easily be changed. \n",
    "        \n",
    "        Also, the default label will be traffic volume, but we can change that by specifying any column we choose. '''\n",
    "    def plot(self, model=None, plot_col='traffic_volume', max_subplots=3):\n",
    "        # get the data\n",
    "        inputs, labels = self.sample_batch\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        \n",
    "        for n in range(max_n):\n",
    "            plt.subplot(3, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col} [scaled]')\n",
    "            # Plot the inputs. They will appear as a continuous blue line with dots . !\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "                label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "                label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "                continue\n",
    "            # Plot the labels (actual values). They will appear as green squares.\n",
    "            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                        edgecolors='k', marker='s', label='Labels', c='green', s=64)\n",
    "            if model is not None:\n",
    "                predictions = model(inputs)\n",
    "            # Plot the predictions. They will appear as red crosses.\n",
    "            plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                        marker='X', edgecolors='k', label='Predictions', c='red', s=64)\n",
    "\n",
    "            if n == 0: \n",
    "                plt.legend()\n",
    "\n",
    "        plt.xlabel('Time (h)')\n",
    "    \n",
    "    ''' Format the dataset into tensors so that it can be fed to the DL models.\n",
    "        TensorFlow comes with a very handy function called timeseries_dataset_from_array(), \n",
    "        which creates a dataset of sliding windows, given an array.'''\n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "            # pass in the data. This corresponds to our training set, validation set or test set.\n",
    "            data=data,\n",
    "            # targets are set to None, as they are handled by the split_to_input_labels() function.\n",
    "            targets=None,\n",
    "            # set the total length of the array, which is equal to the total window length.\n",
    "            sequence_length=self.total_window_size,\n",
    "            # set stride = the number of timesteps separating each sequence. \n",
    "            # if you want the sequences to be consecutive, so sequence_stride=1.\n",
    "            sequence_stride=1,\n",
    "            # shuffle the sequences. Keep in mind that the data is still in chronological order. \n",
    "            # we are simply shuffling the order of the sequences, which makes the model more robust (see lecture slides).\n",
    "            shuffle=True,\n",
    "            # set the number of sequences in a single batch.\n",
    "            batch_size=32\n",
    "        )\n",
    "        \n",
    "        ds = ds.map(self.split_to_inputs_labels)\n",
    "        return ds\n",
    "    \n",
    "    ''' Define some properties to apply the make_dataset() function on the training, validation and testing sets.'''\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "    \n",
    "    # Get a sample batch of data for visualization purposes. \n",
    "    # If the sample batch does not exist, then retrieve a sample batch and cache it.\n",
    "    @property\n",
    "    def sample_batch(self):\n",
    "        result = getattr(self, '_sample_batch', None)\n",
    "        if result is None:\n",
    "            result = next(iter(self.train))\n",
    "            self._sample_batch = result\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50a8a28",
   "metadata": {},
   "source": [
    "## 13.2 Applying baseline models\n",
    "### 13.2.1 Single-step baseline model\n",
    "\n",
    "We’ll first implement a single-step model as a baseline. In a single-step model, the input is one timestep and the output is the prediction of the next timestep.\n",
    "The first step is to generate a window of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c53cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' Since we are defining a single-step model, the input width is 1, the label width is 1 \n",
    "and the shift is also 1, since the model predicts the next timestep. \n",
    "\n",
    "Our target variable is the volume of traffic.\n",
    "\n",
    "For plotting purposes, we’ll define a wider window so we can visualize many predictions of our model. \n",
    "Otherwise, we could only visualize one input data point and one output prediction, which is not very interesting.'''\n",
    "\n",
    "single_step_window = DataWindow(input_width=1, label_width=1, shift=1, label_columns=['traffic_volume']) \n",
    "wide_window = DataWindow(input_width=24, label_width=24, shift=1, label_columns=['traffic_volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a482c7-7569-43ef-9093-5987a33ea5d4",
   "metadata": {},
   "source": [
    "The simplest prediction we can make is the last observed value. \n",
    "Basically, the prediction is simply copying the input data point to the output of the next time step. \n",
    "This is implemented by the class SingleStepBaseline. \n",
    "As you can see in the code below, the Baseline class can also be used as a multi-output model, so not for one target only. \n",
    "\n",
    "However for now, we will focus on a single-step model for one one target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a142946",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SingleStepBaseline(Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "        \n",
    "    '''\n",
    "    The call() method in a class (TensorFlow/Keras neural networks) defines how the model behaves when it's called with input data.\n",
    "    So let us overwrite it and treat 3 different cases and tell it how to behave.\n",
    "    '''\n",
    "    def call(self, inputs):\n",
    "        # CASE 1:\n",
    "        # If no target is specified, we return all columns. \n",
    "        # This is useful for multi-output models where all columns are to be predicted.\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        \n",
    "        # CASE 2:\n",
    "        # If we specify a list of targets, it will return the specified columns only. \n",
    "        # Again, this is used for multi-output models.\n",
    "        ''' \n",
    "            - The model loops through each index.\n",
    "            - Selects each corresponding column from the input tensor.\n",
    "            - Expands the dimension (tf.newaxis) to ensure correct tensor shape.\n",
    "            - Concatenates all these selected columns into a new output tensor.\n",
    "        '''\n",
    "        elif isinstance(self.label_index, list):\n",
    "            tensors = []\n",
    "            \n",
    "            for index in self.label_index:\n",
    "                result = inputs[:, :, index]\n",
    "                result = result[:, :, tf.newaxis]\n",
    "                tensors.append(result)\n",
    "            \n",
    "            return tf.concat(tensors, axis=-1)\n",
    "        \n",
    "        # CASE 3:\n",
    "        # Return the input for one given target variable only.\n",
    "        result = inputs[:, :, self.label_index]\n",
    "        \n",
    "        return result[:,:,tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c28b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a dictionary with the name and index of each column in the training set.\n",
    "column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "\n",
    "# Pass the index of the target column into the Baseline class.\n",
    "baseline_last = SingleStepBaseline(label_index=column_indices['traffic_volume'])\n",
    "\n",
    "''' TensorFlow requires us to provide a loss function and a metric of evaluation. \n",
    "\n",
    "    We are going to use the mean squared error (MSE) as a loss function. \n",
    "    It it penalizes large errors and it generally yields well-fitted models. \n",
    "    \n",
    "    For the evaluation metric, we’ll use the mean absolute error (MAE) for its ease of interpretation.\n",
    "    \n",
    "    Compile the model to generate the predictions. \n",
    "    \n",
    "    As a reminder: compile() configures your model for training. It specifies how to optimize weights (optimizer), \n",
    "    how to measure success (loss) and how to report performance metrics (see above).\n",
    "'''\n",
    "baseline_last.compile(loss=MeanSquaredError(), metrics=[MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f43f423-a59b-407e-a357-2794f9721feb",
   "metadata": {},
   "source": [
    "TensorFlow conveniently comes with the evaluate method, which allows for comparing the predictions to the actual values easily and calculate the error metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba77274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting purposes, we’ll define a wider window so we can visualize many predictions of our model. \n",
    "# Otherwise, we could only visualize one input data point and one output prediction, which is in fact not very interesting.\n",
    "wide_window.plot(baseline_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f8be0-a078-4eae-8388-ac3205a7b120",
   "metadata": {},
   "source": [
    "The crosses at each timestep are simply the last known value, meaning that we have a baseline that works as expected. \n",
    "Your plot may differ from the one of your class mates, as the cached sample batch changes every time a data window is initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c603ba9-5dcb-4c4f-baf5-e6c12b0c497e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_performance = {}\n",
    "performance = {}\n",
    "\n",
    "val_performance['Baseline - Last'] = baseline_last.evaluate(single_step_window.val)\n",
    "performance['Baseline - Last'] = baseline_last.evaluate(single_step_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c9c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('val_performance=', val_performance['Baseline - Last'][1])\n",
    "print('test_performance', performance['Baseline - Last'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc5e90",
   "metadata": {},
   "source": [
    "### 13.2.2 Multi-step baseline models \n",
    "\n",
    "Now, we will forecast the traffic volume for the next 24 hours of data given an input of 24 hours.\n",
    "Again, the first step is to generate the appropriate window of data. \n",
    "In order to predict 24 timesteps into the future with an input of 24 hours, \n",
    "the input width is 24, the label width is 24 and the shift is also 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ff987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_window = DataWindow(input_width=24, label_width=24, shift=24, label_columns=['traffic_volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc55a839",
   "metadata": {},
   "source": [
    "#### Predicting the last known value for the next 24 timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStepLastBaseline(Model):\n",
    "    # the same init() as in the previous class\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "    \n",
    "    # overwrite the call() method and specify what to do\n",
    "    ''' If no target is specified, return the last known value of all columns over the next 24 timesteps.\n",
    "        Return the last known value of the target column over the next 24 timesteps, otherwise. '''\n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return tf.tile(inputs[:, -1:, :], [1, 24, 1]) # here it happens\n",
    "        return tf.tile(inputs[:, -1:, self.label_index:], [1, 24, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9839f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_baseline_last = MultiStepLastBaseline(label_index=column_indices['traffic_volume'])\n",
    "ms_baseline_last.compile(loss=MeanSquaredError(), metrics=[MeanAbsoluteError()])\n",
    "\n",
    "ms_val_performance = {}\n",
    "ms_test_performance = {}\n",
    "\n",
    "ms_val_performance['Baseline - Last']  = ms_baseline_last.evaluate(multi_window.val)\n",
    "ms_test_performance['Baseline - Last'] = ms_baseline_last.evaluate(multi_window.test, verbose=0)\n",
    "\n",
    "print('ms_val_performance=' , ms_val_performance['Baseline - Last'][1])\n",
    "print('ms_test_performance=',ms_test_performance['Baseline - Last'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_window.plot(ms_baseline_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857981d3-e95a-49ae-a4bb-3b8e59dbf9c7",
   "metadata": {},
   "source": [
    "Predicting the last known value for the next 24 timesteps. We can see that the predictions,\n",
    "shown as crosses, correspond to the last value of the input sequence, so our baseline behaves as expected.\n",
    "\n",
    "However, there is no need to comment on the precision, right!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6377809",
   "metadata": {},
   "source": [
    "#### Repeating the input sequence - Predicting the last 24 timesteps as the next 24 timesteps\n",
    "\n",
    "Let us implement a second baseline for multi-step models, which simply returns the input sequence. \n",
    "This means that the prediction for the next 24 hours will simply be the last known 24 hours of data. \n",
    "This is implemented by means of the RepeatBaseline class as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b21721",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepeatBaseline(Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "    \n",
    "    # return the input sequence for the given target column\n",
    "    def call(self, inputs):\n",
    "        return inputs[:, :, self.label_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5183f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_baseline_repeat = RepeatBaseline(label_index=column_indices['traffic_volume'])\n",
    "\n",
    "ms_baseline_repeat.compile(loss=MeanSquaredError(), metrics=[MeanAbsoluteError()])\n",
    "\n",
    "ms_val_performance['Baseline - Repeat'] = ms_baseline_repeat.evaluate(multi_window.val)\n",
    "ms_test_performance['Baseline - Repeat'] = ms_baseline_repeat.evaluate(multi_window.test, verbose=0)\n",
    "\n",
    "print('ms_val_performance=' , ms_val_performance['Baseline - Repeat'][1])\n",
    "print('ms_test_performance=',ms_test_performance['Baseline - Repeat'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5433c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_window.plot(ms_baseline_repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948112df-aa1c-4e2a-89fd-b5ad07e24eef",
   "metadata": {},
   "source": [
    "Repeating the input sequence as the predictions. You can clearly see that the predictions (represented as crosses) \n",
    "match exactly the input sequence. You’ll also notice that many predictions overlap the labels, which indicates that this baseline performs quite well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd201d28",
   "metadata": {},
   "source": [
    "### 13.2.3 Multi-output baseline model \n",
    "\n",
    "The final type of model is the multi-output model. \n",
    "In this situation, we predict the traffic volume and the temperature for the next timestep using a single input data point. \n",
    "Essentially, we’re applying the single-step model on both, the traffic volume and temperature, making it a single-step multi-output model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0e43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that we pass in both temp and traffic_volume, as those are the two targets for the multi-output model.\n",
    "''' Since the model takes in one data point and outputs one prediction, \n",
    "we want to initialize a wider window of data to visualize many predictions over many timesteps (compare with the first baseline model).'''\n",
    "\n",
    "mo_single_step_window = DataWindow(input_width=1, label_width=1, shift=1, label_columns=['temp','traffic_volume']) \n",
    "mo_wide_window = DataWindow(input_width=24, label_width=24, shift=1, label_columns=['temp','traffic_volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4fd901",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(column_indices['traffic_volume']) # prints 2 \n",
    "print(column_indices['temp']) # prints 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b13f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, here the indices from above steps are used\n",
    "# the rest is the same as always\n",
    "mo_baseline_last = SingleStepBaseline(label_index=[0, 2])\n",
    "\n",
    "mo_baseline_last.compile(loss=MeanSquaredError(), metrics=[MeanAbsoluteError()])\n",
    "\n",
    "mo_val_performance = {}\n",
    "mo_test_performance = {}\n",
    "\n",
    "mo_val_performance['Baseline - Last']  = mo_baseline_last.evaluate(mo_wide_window.val)\n",
    "mo_test_performance['Baseline - Last'] = mo_baseline_last.evaluate(mo_wide_window.test, verbose=0)\n",
    "\n",
    "print('mo_val_performance=',  mo_val_performance['Baseline - Last'][1])\n",
    "print('mo_test_performance=',mo_test_performance['Baseline - Last'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bed09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the wieder window is used for visualization \n",
    "mo_wide_window.plot(mo_baseline_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893225fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_wide_window.plot(model=mo_baseline_last, plot_col='temp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
