{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "jvQrM5lFU9DJ",
   "metadata": {
    "id": "jvQrM5lFU9DJ"
   },
   "source": [
    "<img src=\"https://www.th-koeln.de/img/logo.svg\" style=\"float:right;\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YbrYVG1XU_3u",
   "metadata": {
    "id": "YbrYVG1XU_3u"
   },
   "source": [
    "# 11th exercise: <font color=\"#C70039\">Vector Autoregressive Models - VAR: Dpi/Cons Forecast</font>\n",
    "* Course: <a href=\"https://www.gernotheisenberg.de/time_series_forecasting.html\">Time Series Forecasting (TSF)</a>\n",
    "* Lecturer: <a href=\"https://www.gernotheisenberg.de/uebermich.html\">Gernot Heisenberg</a>\n",
    "* Date:   19.03.2025\n",
    "\n",
    "<img src=\"./images/var.jpeg\" style=\"float: center;\" width=\"450\">\n",
    "\n",
    "---------------------------------\n",
    "**GENERAL NOTE 1**:\n",
    "Please make sure you are reading the entire notebook, since it contains a lot of information on your tasks (e.g. regarding the set of certain paramaters or a specific computational trick), and the written mark downs as well as comments contain a lot of information on how things work together as a whole.\n",
    "\n",
    "**GENERAL NOTE 2**:\n",
    "* Please, when commenting source code, just use English language only.\n",
    "* When describing an observation please use English language, too\n",
    "* This applies to all exercises throughout this course.  \n",
    "\n",
    "---------------------\n",
    "\n",
    "### <font color=\"ce33ff\">DESCRIPTION OF THE NOTEBOOK CONTENT</font>:\n",
    "This notebook show you how to develop four different baseline models to compare your real forecasts to.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### <font color=\"FFC300\">TASKS</font>:\n",
    "The tasks that you need to work on within this notebook are always indicated below as bullet points.\n",
    "If a task is more challenging and consists of several steps, this is indicated as well.\n",
    "Make sure you have worked down the task list and commented your doings.\n",
    "This should be done by using markdown.<br>\n",
    "<font color=red>Make sure you don't forget to specify your name and your matriculation number in the notebook.</font>\n",
    "\n",
    "**YOUR TASKS in this exercise are as follows**:\n",
    "1. import the notebook to Google Colab or use your local machine.\n",
    "2. make sure you specified you name and your matriculation number in the header below my name and date.\n",
    "    * set the date too and remove mine.\n",
    "3. read the entire notebook carefully\n",
    "    * add comments whereever you feel it necessary for better understanding\n",
    "    * run the notebook for the first time.\n",
    "    * understand the output\n",
    "4. Use a VARMA model to predict realdpi and realcons\n",
    "    * Since now, we used a VAR(p) model. However, we used the VARMAX function from statsmodels to do so, meaning that we can easily extend the VAR(p) model to a VARMA(p,q) model. \n",
    "    * In this exercise, use a VARMA(p,q) model to forecast realdpi and realcons.\n",
    "    * Use the same train and test sets as in this chapter.\n",
    "    * Generate a list of unique (p,q) combinations.\n",
    "    * Rename the optimize_VAR function to optimize_VARMA, and adapt it to loop over all unique (p,q) combinations. \n",
    "    * Select the model with the lowest AIC, and perform the Granger causality test.\n",
    "    * Pass in the largest order among (p,q). Is the VARMA(p,q) model valid?\n",
    "    * Perform residual analysis.\n",
    "    * Make forecasts on a four-step window over the test set. Use the last known value method as a baseline.\n",
    "    * Calculate the MAPE. \n",
    "    * Is it lower or higher than that of our VAR(3) model?\n",
    "-----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KPWUOFWzVF5c",
   "metadata": {
    "id": "KPWUOFWzVF5c"
   },
   "source": [
    "## 11.0 Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-klein",
   "metadata": {
    "id": "powerful-klein",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests, adfuller\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ukR6BFjfVK59",
   "metadata": {
    "id": "ukR6BFjfVK59"
   },
   "source": [
    "## 11.1 Data loading & visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-gothic",
   "metadata": {
    "id": "signed-gothic",
    "outputId": "18ff1090-db25-4849-b110-30700c1dc3ab",
    "tags": []
   },
   "outputs": [],
   "source": [
    "macro_econ_data = sm.datasets.macrodata.load_pandas().data\n",
    "macro_econ_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-decline",
   "metadata": {
    "id": "personalized-decline",
    "outputId": "2fc00248-a704-4bac-d72f-488a22b8d402",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(10,8))\n",
    "\n",
    "ax1.plot(macro_econ_data['realdpi'])\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Real disposable income (k$)')\n",
    "ax1.set_title('realdpi')\n",
    "ax1.spines['top'].set_alpha(0)\n",
    "\n",
    "ax2.plot(macro_econ_data['realcons'])\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Real consumption (k$)')\n",
    "ax2.set_title('realcons')\n",
    "ax2.spines['top'].set_alpha(0)\n",
    "\n",
    "plt.xticks(np.arange(0, 208, 16), np.arange(1959, 2010, 4))\n",
    "\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-albania",
   "metadata": {
    "id": "raising-albania"
   },
   "source": [
    "## 11.2 Augmented Dickey-Fuller test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-shoulder",
   "metadata": {
    "id": "instructional-shoulder",
    "outputId": "4420f5ee-0958-4f97-a81d-65d327505826",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ad_fuller_result_1 = adfuller(macro_econ_data['realdpi'])\n",
    "\n",
    "print('realdpi')\n",
    "print(f'ADF Statistic: {ad_fuller_result_1[0]}')\n",
    "print(f'p-value: {ad_fuller_result_1[1]}')\n",
    "\n",
    "print('\\n---------------------\\n')\n",
    "\n",
    "ad_fuller_result_2 = adfuller(macro_econ_data['realcons'])\n",
    "\n",
    "print('realcons')\n",
    "print(f'ADF Statistic: {ad_fuller_result_2[0]}')\n",
    "print(f'p-value: {ad_fuller_result_2[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-fields",
   "metadata": {
    "id": "sealed-fields",
    "outputId": "420186c1-8bfb-4d94-fbdf-ed1757fe17f8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ad_fuller_result_1 = adfuller(macro_econ_data['realdpi'].diff()[1:])\n",
    "\n",
    "print('realdpi')\n",
    "print(f'ADF Statistic: {ad_fuller_result_1[0]}')\n",
    "print(f'p-value: {ad_fuller_result_1[1]}')\n",
    "\n",
    "print('\\n---------------------\\n')\n",
    "\n",
    "ad_fuller_result_2 = adfuller(macro_econ_data['realcons'].diff()[1:])\n",
    "\n",
    "print('realcons')\n",
    "print(f'ADF Statistic: {ad_fuller_result_2[0]}')\n",
    "print(f'p-value: {ad_fuller_result_2[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449ceeef-91cd-4c71-8ec6-4ecf3ee0805a",
   "metadata": {},
   "source": [
    "After 1st order differencing both time series are stationary now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C8MM7FGnVXWe",
   "metadata": {
    "id": "C8MM7FGnVXWe"
   },
   "source": [
    "## 11.3 Optimizing the VAR (VARMAX) model\n",
    "\n",
    "we will use a VAR(p) model. However, we used the VARMAX function from statsmodels to do so. \n",
    "This means that we can easily extend the VAR(p) model to a VARMA(p,q) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-drink",
   "metadata": {
    "id": "partial-drink",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from tqdm import tqdm_notebook\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "\n",
    "def optimize_VAR(endog: Union[pd.Series, list]) -> pd.DataFrame:\n",
    "\n",
    "    results = []\n",
    "    # Vary the order p from 0 to 14\n",
    "    for i in tqdm_notebook(range(15)): \n",
    "        try:\n",
    "            model = VARMAX(endog, order=(i, 0)).fit(dips=False) # MA is zero -> VAR and not VARMA\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        aic = model.aic\n",
    "        results.append([i, aic])\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.columns = ['p', 'AIC']\n",
    "\n",
    "    result_df = result_df.sort_values(by='AIC', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bb319e-1df3-489c-a8ad-50f0ce0d5ac7",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "We must define the train and test sets. In this case, weâ€™ll use 80% of the data for training and 20% for testing. \n",
    "This means that the last 40 data points will be used for testing and the rest is used for training. \n",
    "\n",
    "Since the VAR(p) model requires both series to be stationary, weâ€™ll split on the differenced dataset and feed \n",
    "the differenced training set to the optimize_VAR function()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-street",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "4bc86cc74f214e35b1dc3452848d499e"
     ]
    },
    "id": "robust-street",
    "outputId": "40c68fc0-d606-47cc-e58c-90c3cf5ae34e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "endog = macro_econ_data[['realdpi', 'realcons']]\n",
    "\n",
    "endog_diff = macro_econ_data[['realdpi', 'realcons']].diff()[1:]\n",
    "\n",
    "train = endog_diff[:162]\n",
    "test = endog_diff[162:]\n",
    "\n",
    "result_df = optimize_VAR(train)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c91eac9-040c-48be-a3fb-46d09e1839fc",
   "metadata": {},
   "source": [
    "Now, let's prepare for the Granger-Causality-Test.\n",
    "\n",
    "The null hypothesis for this test states that y_2,t does not Granger-cause y_1,t. Again,\n",
    "we will use the p-value with a critical value of 0.05 to determine whether we will reject\n",
    "the null hypothesis or not. In the case where the returned p-value of the Granger causality\n",
    "test is less than 0.05, we can reject the null hypothesis and say that y_2,t Grangercauses\n",
    "y_1,t.\n",
    "\n",
    "<font color = red>IMPORTANT NOTE:</font>\n",
    "\n",
    "The reason the Granger causality test is performed after the VAR(p) model is selected is simply\n",
    "because the test requires us to specify the number of lags to include in the test, \n",
    "which is equivalent to the order of the model. \n",
    "\n",
    "For example, since p=3 the Granger causality test will determine if the past three\n",
    "values of a time series are statistically significant in forecasting the other time series.\n",
    "\n",
    "Make sure that you check for Causality bi-directional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-valuation",
   "metadata": {
    "id": "experimental-valuation",
    "outputId": "2bbb3715-eb5f-485d-a3e3-0a96faf72bf5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('realcons Granger-causes realdpi?\\n')\n",
    "print('------------------')\n",
    "granger_1 = grangercausalitytests(macro_econ_data[['realdpi', 'realcons']].diff()[1:], [3])\n",
    "\n",
    "print('\\nrealdpi Granger-causes realcons?\\n')\n",
    "print('------------------')\n",
    "granger_2 = grangercausalitytests(macro_econ_data[['realcons', 'realdpi']].diff()[1:], [3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4eda4-fd5e-4e62-b769-55a57953e51d",
   "metadata": {},
   "source": [
    "#### INTERMEDIATE RESULT\n",
    "\n",
    "Running the Granger causality test for both variables returns a p-value smaller than\n",
    "0.05 in both cases. Therefore, we can reject the null hypothesis and conclude that\n",
    "realdpi Granger-causes realcons and realcons Granger-causes realdpi. Our\n",
    "VAR(3) model is thus valid and can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xf9Z3p_GVvnn",
   "metadata": {
    "id": "Xf9Z3p_GVvnn"
   },
   "source": [
    "## 11.4 Model building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-closing",
   "metadata": {
    "id": "outdoor-closing",
    "outputId": "a273104f-9586-4abc-8b59-da1356a14b60",
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = VARMAX(train, order=(3,0))\n",
    "best_model_fit = best_model.fit(disp=False)\n",
    "\n",
    "print(best_model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-criterion",
   "metadata": {
    "id": "peaceful-criterion",
    "outputId": "9c7e2ceb-e99f-4f12-a2e0-da11db2df682",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# realdpi\n",
    "best_model_fit.plot_diagnostics(figsize=(10,8), variable=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-appraisal",
   "metadata": {
    "id": "balanced-appraisal",
    "outputId": "ab8acd23-a51a-4e13-b6e6-9df0ffcab948",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# realcons\n",
    "best_model_fit.plot_diagnostics(figsize=(10,8), variable=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-painting",
   "metadata": {
    "id": "timely-painting",
    "outputId": "e31f3b7f-22f4-4eef-8788-be7d2d48232a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "realgdp_residuals = best_model_fit.resid['realdpi']\n",
    "\n",
    "lbvalue = acorr_ljungbox(realgdp_residuals, np.arange(1, 11, 1))\n",
    "\n",
    "print(lbvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-nicholas",
   "metadata": {
    "id": "relevant-nicholas",
    "outputId": "c229862b-c2c3-418c-f562-8a5ae91c6b00",
    "tags": []
   },
   "outputs": [],
   "source": [
    "realcons_residuals = best_model_fit.resid['realcons']\n",
    "\n",
    "lb_value = acorr_ljungbox(realcons_residuals, np.arange(1, 11, 1))\n",
    "\n",
    "print(lb_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b4f142-3cf7-45b0-80af-0930feb6724d",
   "metadata": {},
   "source": [
    "#### INTERMEDIATE RESULTS\n",
    "\n",
    "Since the model passed both the qualitative and quantitative aspects of residual analysis, we can move on to forecasting realcons and realdpi using a VAR(3) model.\n",
    "We will compare the VAR(3) model to a baseline that simply predicts the last observed value. \n",
    "\n",
    "Weâ€™ll forecast four steps into the future, which is equivalent to forecasting one full year as the data is sampled quarterly. \n",
    "Weâ€™ll thus perform a rolling forecast four steps into the future over the entire length of the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j_FXj8HcWRLI",
   "metadata": {
    "id": "j_FXj8HcWRLI"
   },
   "source": [
    "## 11.5 Forecasting dpi/cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-genre",
   "metadata": {
    "id": "committed-genre",
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' \n",
    "    define the forecasting function in the same manner as many notebooks ago (compare the function to earlier implementations).\n",
    "    It will need to output predictions for both realdpi and realcons, so we must return two lists containing forecasts.\n",
    "'''\n",
    "def rolling_forecast(df: pd.DataFrame, train_len: int, horizon: int, window: int, method: str) -> list:\n",
    "\n",
    "    total_len = train_len + horizon\n",
    "    end_idx = train_len\n",
    "\n",
    "    # VAR model\n",
    "    if method == 'VAR':\n",
    "\n",
    "        realdpi_pred_VAR = []\n",
    "        realcons_pred_VAR = []\n",
    "\n",
    "        for i in range(train_len, total_len, window):\n",
    "            model = VARMAX(df[:i], order=(3,0)) #p=3, q=0\n",
    "            res = model.fit(disp=False)\n",
    "            predictions = res.get_prediction(0, i + window - 1)\n",
    "\n",
    "            oos_pred_realdpi = predictions.predicted_mean.iloc[-window:]['realdpi']\n",
    "            oos_pred_realcons = predictions.predicted_mean.iloc[-window:]['realcons']\n",
    "\n",
    "            realdpi_pred_VAR.extend(oos_pred_realdpi)\n",
    "            realcons_pred_VAR.extend(oos_pred_realcons)\n",
    "\n",
    "        return realdpi_pred_VAR, realcons_pred_VAR\n",
    "\n",
    "    # baseline model\n",
    "    elif method == 'last':\n",
    "        realdpi_pred_last = []\n",
    "        realcons_pred_last = []\n",
    "\n",
    "        for i in range(train_len, total_len, window):\n",
    "\n",
    "            realdpi_last = df[:i].iloc[-1]['realdpi']\n",
    "            realcons_last = df[:i].iloc[-1]['realcons']\n",
    "\n",
    "            realdpi_pred_last.extend(realdpi_last for _ in range(window))\n",
    "            realcons_pred_last.extend(realcons_last for _ in range(window))\n",
    "\n",
    "        return realdpi_pred_last, realcons_pred_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-friend",
   "metadata": {
    "id": "inclusive-friend",
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_LEN = len(train)\n",
    "HORIZON = len(test)\n",
    "# The window is 4, since we want to forecast four time steps into the future at a time, \n",
    "# which is equivalent to 1 year\n",
    "WINDOW = 4 \n",
    "\n",
    "realdpi_pred_VAR, realcons_pred_VAR = rolling_forecast(endog_diff, TRAIN_LEN, HORIZON, WINDOW, 'VAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-accident",
   "metadata": {
    "id": "reflected-accident",
    "outputId": "ea8fd047-77d8-419c-c7c7-b363f2ff5eb0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = endog[163:]\n",
    "\n",
    "# remember we are working with the differenced values, thus we need to integrate\n",
    "test['realdpi_pred_VAR'] = pd.Series()\n",
    "test['realdpi_pred_VAR'] = endog.iloc[162]['realdpi'] + np.cumsum(realdpi_pred_VAR)\n",
    "\n",
    "test['realcons_pred_VAR'] = pd.Series()\n",
    "test['realcons_pred_VAR'] = endog.iloc[162]['realcons'] + np.cumsum(realcons_pred_VAR)\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-battlefield",
   "metadata": {
    "id": "wanted-battlefield",
    "outputId": "0e772137-d025-4595-bb67-f64eaa3ad360",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add the baseline model result\n",
    "realdpi_pred_last, realcons_pred_last = rolling_forecast(endog, TRAIN_LEN, HORIZON, WINDOW, 'last')\n",
    "\n",
    "test['realdpi_pred_last'] = realdpi_pred_last\n",
    "test['realcons_pred_last'] = realcons_pred_last\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-founder",
   "metadata": {
    "id": "cleared-founder",
    "outputId": "fcc320d6-0f4e-44ce-f288-93a83777f859",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(10,8))\n",
    "\n",
    "ax1.plot(macro_econ_data['realdpi'])\n",
    "ax1.plot(test['realdpi_pred_VAR'], 'k--', label='VAR')\n",
    "ax1.plot(test['realdpi_pred_last'], 'r:', label='last')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Real disposable income ($))')\n",
    "ax1.set_title('realdpi')\n",
    "ax1.spines['top'].set_alpha(0)\n",
    "ax1.axvspan(163, 202, color='#808080', alpha=0.2)\n",
    "ax1.set_xlim(100, 202)\n",
    "ax1.legend(loc=2)\n",
    "\n",
    "ax2.plot(macro_econ_data['realcons'])\n",
    "ax2.plot(test['realcons_pred_VAR'], 'k--', label='VAR')\n",
    "ax2.plot(test['realcons_pred_last'], 'r:', label='last')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Real consumption (k$)')\n",
    "ax2.set_title('realcons')\n",
    "ax2.spines['top'].set_alpha(0)\n",
    "ax2.axvspan(163, 202, color='#808080', alpha=0.2)\n",
    "ax2.set_xlim(100, 202)\n",
    "ax2.legend(loc=2)\n",
    "\n",
    "plt.xticks(np.arange(0, 208, 16), np.arange(1959, 2010, 4))\n",
    "plt.xlim(100, 202)\n",
    "\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e439cb7e-3a56-49a5-bd4c-846e7553c7cc",
   "metadata": {},
   "source": [
    "#### RESULTS 1:\n",
    "You can see that both lines are very close to the actual values of the test set, making it hard to visually determine which method is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-gilbert",
   "metadata": {
    "id": "guilty-gilbert",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-registrar",
   "metadata": {
    "id": "corporate-registrar",
    "tags": []
   },
   "outputs": [],
   "source": [
    "mape_realdpi_VAR = mape(test['realdpi'], test['realdpi_pred_VAR'])\n",
    "mape_realdpi_last = mape(test['realdpi'], test['realdpi_pred_last'])\n",
    "\n",
    "mape_realcons_VAR = mape(test['realcons'], test['realcons_pred_VAR'])\n",
    "mape_realcons_last = mape(test['realcons'], test['realcons_pred_last'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-tracy",
   "metadata": {
    "id": "sound-tracy",
    "outputId": "0825f4bb-88da-4321-b22b-93c9919ed603",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10,6))\n",
    "\n",
    "x = ['last', 'VAR']\n",
    "y1 = [mape_realdpi_last, mape_realdpi_VAR]\n",
    "y2 = [mape_realcons_last, mape_realcons_VAR]\n",
    "\n",
    "ax1.bar(x, y1)\n",
    "ax1.set_xlabel('Methods')\n",
    "ax1.set_ylabel('MAPE (%)')\n",
    "ax1.set_title('realdpi')\n",
    "ax1.set_ylim(0, 3.5)\n",
    "\n",
    "ax2.bar(x,y2)\n",
    "ax2.set_xlabel('Methods')\n",
    "ax2.set_ylabel('MAPE (%)')\n",
    "ax2.set_title('realcons')\n",
    "ax2.set_ylim(0, 3)\n",
    "\n",
    "for index, value in enumerate(y1):\n",
    "    ax1.text(x=index, y=value + 0.05, s=str(round(value,2)), ha='center')\n",
    "\n",
    "for index, value in enumerate(y2):\n",
    "    ax2.text(x=index, y=value + 0.05, s=str(round(value,2)), ha='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b1e1aa-a483-418d-afbe-cea206e75c61",
   "metadata": {},
   "source": [
    "#### RESULTS 2:\n",
    "\n",
    "We can easily see that the VAR(3) model performs worse than the baseline forecasting the realdpi but better than the baseline for realcons. \n",
    "This is an ambiguous situation. There is no clear result, since the model does not outperform the baseline in both situations.\n",
    "\n",
    "We can hypothesize that in the case of realdpi, realcons is not predictive enough to make more accurate forecasts than the baseline, even though the Granger causality test passed. Therefore, we should resort to using a variation of the SARIMAX model to predict realdpi. \n",
    "\n",
    "Thus, we could conclude that the VAR(3) model is not sufficient to accurately forecast realdpi and realcons. \n",
    "We could maybe suggest using two separate models, which could include realdpi and realcons as exogenous variables, while also potentially including moving average terms."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
